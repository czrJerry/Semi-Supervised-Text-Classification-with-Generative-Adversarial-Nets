{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0m5KR34gmRH"
   },
   "source": [
    "Let's GO!\n",
    "\n",
    "Required Imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: transformers in ./miniconda3/lib/python3.8/site-packages (4.3.2)\n",
      "Requirement already satisfied: filelock in ./miniconda3/lib/python3.8/site-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: sacremoses in ./miniconda3/lib/python3.8/site-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in ./miniconda3/lib/python3.8/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./miniconda3/lib/python3.8/site-packages (from transformers) (1.21.4)\n",
      "Requirement already satisfied: packaging in ./miniconda3/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./miniconda3/lib/python3.8/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: requests in ./miniconda3/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./miniconda3/lib/python3.8/site-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./miniconda3/lib/python3.8/site-packages (from packaging->transformers) (3.0.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./miniconda3/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./miniconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./miniconda3/lib/python3.8/site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: joblib in ./miniconda3/lib/python3.8/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in ./miniconda3/lib/python3.8/site-packages (from sacremoses->transformers) (8.1.3)\n",
      "Requirement already satisfied: six in ./miniconda3/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: datasets in ./miniconda3/lib/python3.8/site-packages (2.3.2)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in ./miniconda3/lib/python3.8/site-packages (from datasets) (8.0.0)\n",
      "Requirement already satisfied: multiprocess in ./miniconda3/lib/python3.8/site-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in ./miniconda3/lib/python3.8/site-packages (from datasets) (2022.5.0)\n",
      "Requirement already satisfied: packaging in ./miniconda3/lib/python3.8/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in ./miniconda3/lib/python3.8/site-packages (from datasets) (0.7.0)\n",
      "Requirement already satisfied: pandas in ./miniconda3/lib/python3.8/site-packages (from datasets) (1.4.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./miniconda3/lib/python3.8/site-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./miniconda3/lib/python3.8/site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: dill<0.3.6 in ./miniconda3/lib/python3.8/site-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: xxhash in ./miniconda3/lib/python3.8/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: responses<0.19 in ./miniconda3/lib/python3.8/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: aiohttp in ./miniconda3/lib/python3.8/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./miniconda3/lib/python3.8/site-packages (from datasets) (1.21.4)\n",
      "Requirement already satisfied: filelock in ./miniconda3/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./miniconda3/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./miniconda3/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./miniconda3/lib/python3.8/site-packages (from packaging->datasets) (3.0.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./miniconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./miniconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./miniconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./miniconda3/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./miniconda3/lib/python3.8/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in ./miniconda3/lib/python3.8/site-packages (from aiohttp->datasets) (2.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./miniconda3/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./miniconda3/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./miniconda3/lib/python3.8/site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./miniconda3/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./miniconda3/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./miniconda3/lib/python3.8/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in ./miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UIqpm34x2rms",
    "outputId": "376fd5d8-2dd4-4573-e98d-50471af0f686"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import io\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn as nn\n",
    "from transformers import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import (set_seed,\n",
    "                          TrainingArguments,\n",
    "                          Trainer,\n",
    "                          GPT2Config,\n",
    "                          GPT2Tokenizer,\n",
    "                          AdamW, \n",
    "                          get_linear_schedule_with_warmup,\n",
    "                          GPT2ForSequenceClassification)\n",
    "#!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "#!pip install sentencepiece\n",
    "\n",
    "##Set random values\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "if torch.cuda.is_available():\n",
    "  torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "2434bd843c194f9a98a52ed61f18dc6b",
      "62c32181e5454be4853204fc34d2e005",
      "1a094026b4e74437a099252eaa523a0a",
      "c3bc29808fc84322a5ed0eadec2a395e",
      "129fa07e06f948619468a9f05b0fb1cd",
      "bc56de84e1944f4986e568963cad3859",
      "ee2079f01f524cf1930cf7840f8dd865",
      "89262b565bd74339a096533024105135",
      "e430d1cecc0f45a583294e3a06c4c405",
      "97b6d1467c0446b1bf69495cb81a6010",
      "20814569beb741bb88e33279fc065e3e"
     ]
    },
    "id": "youbtoYN4yWW",
    "outputId": "6ba3d39a-f623-4799-faae-6839ab17b96b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset amazon_reviews_multi (/root/.cache/huggingface/datasets/amazon_reviews_multi/en/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb42ccc737e4aa3a956658a42dbb023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"amazon_reviews_multi\",'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aXS24ico5-6Q",
    "outputId": "af99ddfa-0ad3-4d52-d7ce-86799acd460c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review_id': 'en_0964290',\n",
       " 'product_id': 'product_en_0740675',\n",
       " 'reviewer_id': 'reviewer_en_0342986',\n",
       " 'stars': 1,\n",
       " 'review_body': \"Arrived broken. Manufacturer defect. Two of the legs of the base were not completely formed, so there was no way to insert the casters. I unpackaged the entire chair and hardware before noticing this. So, I'll spend twice the amount of time boxing up the whole useless thing and send it back with a 1-star review of part of a chair I never got to sit in. I will go so far as to include a picture of what their injection molding and quality assurance process missed though. I will be hesitant to buy again. It makes me wonder if there aren't missing structures and supports that don't impede the assembly process.\",\n",
       " 'review_title': \"I'll spend twice the amount of time boxing up the whole useless thing and send it back with a 1-star review ...\",\n",
       " 'language': 'en',\n",
       " 'product_category': 'furniture'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "iUXz1fMq8r1h"
   },
   "outputs": [],
   "source": [
    "train_num=len(dataset['train'])\n",
    "test_num=len(dataset['test'])\n",
    "val_num=len(dataset['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KpdbsAMYgS1L",
    "outputId": "a90f67b6-00a1-4da3-8428-0ad33032906c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "5000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(train_num)\n",
    "print(test_num)\n",
    "print(val_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9XbIgB0lraxv"
   },
   "outputs": [],
   "source": [
    "def get_dict(data):\n",
    "  data_dict={}\n",
    "  for i in range(len(data)):\n",
    "    data_dict[data[i]['review_body']]=data[i]['stars']\n",
    "  return data_dict\n",
    "train_dict=get_dict(dataset['train'])\n",
    "test_dict=get_dict(dataset['test'])\n",
    "val_dict=get_dict(dataset['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jYLLW8ZZ8OO1"
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(list(train_dict.items()),columns = ['review_body','stars']) \n",
    "test_df  = pd.DataFrame(list(test_dict.items()),columns = ['review_body','stars'])\n",
    "val_df   = pd.DataFrame(list(test_dict.items()),columns = ['review_body','stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "JlQ2PINeq9B1",
    "outputId": "336459db-e1d6-4152-f49c-b3024fddf5be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stars</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_body\n",
       "stars             \n",
       "1             1000\n",
       "2             1000\n",
       "3             1000\n",
       "4             1000\n",
       "5             1000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.groupby(['stars']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "4dxEiYr6rAW5",
    "outputId": "bef9bdbf-8e1b-4679-ca4d-d01d30830a55"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stars</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_body\n",
       "stars             \n",
       "1            39841\n",
       "2            39930\n",
       "3            39925\n",
       "4            39861\n",
       "5            39869"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby(['stars']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "jiGvSvpprAdB",
    "outputId": "a8a02c50-df71-480e-f911-a01e5ed7aac8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stars</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_body\n",
       "stars             \n",
       "1             1000\n",
       "2             1000\n",
       "3             1000\n",
       "4             1000\n",
       "5             1000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.groupby(['stars']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BsxZBggQreC5",
    "outputId": "ccbc1d34-3b2e-477a-fb78-2e529a5d2345"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199426"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0eJtptXiGorl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "label_list = ['1','2','3','4','5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use 5% label data, the rest as unlabel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_unlabel(train_df):\n",
    "  cv = StratifiedKFold(n_splits=100,shuffle = True,random_state=42)\n",
    "  i=0\n",
    "  unlabel_idx=[]\n",
    "  label_idx=[]\n",
    "  for train_idxs, test_idxs in cv.split(train_df,train_df['stars']):\n",
    "    if i in [i for i in range(0,100,20)]:\n",
    "      label_idx=np.concatenate((label_idx,test_idxs), axis=None)\n",
    "      i+=1\n",
    "    # elif i in range(4,400,2):\n",
    "    #   unlabel_idx=np.concatenate((unlabel_idx,test_idxs), axis=None)\n",
    "    #   i+=1\n",
    "    else:\n",
    "      unlabel_idx=np.concatenate((unlabel_idx,test_idxs), axis=None)\n",
    "      i+=1\n",
    "  return train_df.loc[label_idx,:],train_df.loc[unlabel_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,unlabel_data=get_label_unlabel(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_data： 9972\n",
      "test_data： 5000\n"
     ]
    }
   ],
   "source": [
    "print('label_data：',len(train_df))\n",
    "print('test_data：',len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.reset_index(drop=True,inplace=True)\n",
    "test_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "JQEdhQtTY6HD"
   },
   "outputs": [],
   "source": [
    "def get_qc_examples(data,label=False):\n",
    "  \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "  examples = []\n",
    "  if label==True:\n",
    "    for i in range(len(data)):\n",
    "      x=data.loc[i,'review_body']\n",
    "      y=data.loc[i,'stars']\n",
    "      examples.append((x,y))\n",
    "  else:\n",
    "    for i in range(len(data)):\n",
    "      x=data.loc[i,'review_body']\n",
    "      y='UNK_UNK'\n",
    "      examples.append((x,y))\n",
    "\n",
    "  return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "gCpWSj4BY6MS"
   },
   "outputs": [],
   "source": [
    "#Load the examples\n",
    "labeled_examples = get_qc_examples(train_df,label=True)\n",
    "test_examples = get_qc_examples(test_df,label=True)\n",
    "\n",
    "# original size\n",
    "# train 688  \n",
    "# unlabel 14433\n",
    "# test 972"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bd_-soMPjHQ-",
    "outputId": "a6607fe5-4813-4587-fcdc-35139ae20cf8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LeZgRup520II",
    "outputId": "1818bba7-d531-461c-beff-e4349ba6a591"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA RTX A5000\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AU3ns8Ic7I-h"
   },
   "source": [
    "### Input Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "jw0HC_hU3FUy"
   },
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "#  Transformer parameters\n",
    "#--------------------------------\n",
    "max_seq_length = 64\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Replicate labeled data to balance poorly represented datasets, \n",
    "# e.g., less than 1% of labeled material\n",
    "apply_balance = True\n",
    "\n",
    "#--------------------------------\n",
    "#  Optimization parameters\n",
    "#--------------------------------\n",
    "learning_rate_discriminator = 5e-5\n",
    "epsilon = 1e-8\n",
    "num_train_epochs = 5\n",
    "multi_gpu = True\n",
    "# Scheduler\n",
    "apply_scheduler = False\n",
    "warmup_proportion = 0.1\n",
    "# Print\n",
    "print_each_n_step = 10\n",
    "\n",
    "#--------------------------------\n",
    "#  Adopted Tranformer model\n",
    "#--------------------------------\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "#model_name = \"bert-base-uncased\"\n",
    "#model_name = \"roberta-base\"\n",
    "#model_name = \"albert-base-v2\"\n",
    "#model_name = \"xlm-roberta-base\"\n",
    "#model_name = \"amazon/bort\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WunkB3ifqy09",
    "outputId": "7aff0ce2-8f32-4dc6-fb64-eb7101e020d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuraiton...\n",
      "Loading tokenizer...\n",
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded to `cuda`\n"
     ]
    }
   ],
   "source": [
    "# Get model configuration.\n",
    "print('Loading configuraiton...')\n",
    "model_config = GPT2Config.from_pretrained(pretrained_model_name_or_path=model_name, num_labels=len(label_list))\n",
    "\n",
    "# Get model's tokenizer.\n",
    "print('Loading tokenizer...')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(pretrained_model_name_or_path=model_name,return_tensors=\"pt\")\n",
    "# default to left padding\n",
    "tokenizer.padding_side = \"left\"\n",
    "# Define PAD Token = EOS Token = 50256\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "# Get the actual model.\n",
    "print('Loading model...')\n",
    "transformer = GPT2ForSequenceClassification.from_pretrained(pretrained_model_name_or_path=model_name, config=model_config)\n",
    "\n",
    "# resize model embedding to match new tokenizer\n",
    "transformer.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# fix model padding token id\n",
    "transformer.config.pad_token_id = transformer.config.eos_token_id\n",
    "\n",
    "# Load model to defined device.\n",
    "transformer.to(device)\n",
    "print('Model loaded to `%s`'%device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98,
     "referenced_widgets": [
      "d0b3f99b999e4404b368ffef20afd215",
      "32ebaebc1b9f4c38a9b09b622b74bb4a",
      "e92970194bf147bcafd1ce5e2cd40f6a",
      "b355e5360890461e97f602e7eeb558ec",
      "588b4eb8e8644a659d2e3d7f03ead81b",
      "a46736657d3f4dd9a3588417df8f2b82",
      "fdbfe0cba9f34fee9b676a9b0e4e2c92",
      "47ba2d37dbb84f95be3a9c157d5debb3",
      "e19df474123f435abdae9508b80ad00a",
      "83b2a8bf9a584512950b8c537832c24b",
      "fbda94b20c044d298dc93b228d56d14c",
      "b5e9ed2012ab402786d1d100e8a962fb",
      "c981c49a377444f5b3183ce1b1ec4a17",
      "d0cc3e8debd84b6d9a82fa82600c1390",
      "a033b282afd4425fb82b4bca73c23744",
      "1e228d8f3f5e4c7da48113659ef20d46",
      "4b92fbbaa843493ba899a9c82b500f04",
      "27343e20465f4baca64bbb06059018ec",
      "343014c346ff4a39b498b1c7637feb96",
      "2339fae914374b5d9ad722c51d1587a6",
      "f1a4c983573441529ab0de9a457d9dc7",
      "c084ad84d5d84ad48021c21bd260557d"
     ]
    },
    "id": "U1BHtvmkmGXO",
    "outputId": "2305718a-039f-4ee7-a62f-b887ab0b1e05"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a31198c9ff4f8f8387abb5a5cff271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9972 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6edf117709405e91865643e3752d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length: 256\n"
     ]
    }
   ],
   "source": [
    "lengths_dict = {}\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# get train_label length\n",
    "lengths = []\n",
    "tk0 = tqdm(labeled_examples, total=len(labeled_examples))\n",
    "for text in tk0:\n",
    "    length = len(tokenizer(text[0], add_special_tokens=False)['input_ids'])\n",
    "    lengths.append(length)\n",
    "lengths_dict['label'] = lengths\n",
    "\n",
    "\n",
    "# get test length\n",
    "lengths = []\n",
    "tk0 = tqdm(test_examples, total=len(test_examples))\n",
    "for text in tk0:\n",
    "    length = len(tokenizer(text[0], add_special_tokens=False)['input_ids'])\n",
    "    lengths.append(length)\n",
    "lengths_dict['test'] = lengths\n",
    "    \n",
    "max_len = max(max(lengths_dict['label']),max(lengths_dict['test'])) + 2 # CLS + SEP \n",
    "if max_len>512:\n",
    "  max_seq_length=256\n",
    "else:\n",
    "  max_seq_length = max_len\n",
    "print(f\"max_seq_length: {max_seq_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBhaW5vBfR6B"
   },
   "source": [
    "Functions required to convert examples into Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "fmKL5AD7I4Zg"
   },
   "outputs": [],
   "source": [
    "def generate_data_loader(input_examples, label_map, do_shuffle = False, balance_label_examples = False):\n",
    "  '''\n",
    "  Generate a Dataloader given the input examples, eventually masked if they are \n",
    "  to be considered NOT labeled.\n",
    "  '''\n",
    "  \n",
    "  #-----------------------------------------------\n",
    "  # Generate input examples to the Transformer\n",
    "  #-----------------------------------------------\n",
    "  input_ids = []\n",
    "  input_mask_array = []\n",
    "  label_id_array = []\n",
    "\n",
    "  # Tokenization \n",
    "  for text in input_examples:\n",
    "    encoded_sent = tokenizer.encode(text[0], add_special_tokens=True, max_length=max_seq_length, padding=\"max_length\", truncation=True)\n",
    "    input_ids.append(encoded_sent)\n",
    "    label_id_array.append(label_map[str(text[1])])\n",
    "  \n",
    "  # Attention to token (to ignore padded input wordpieces)\n",
    "  for sent in input_ids:\n",
    "    att_mask = [int(token_id !=50256) for token_id in sent] \n",
    "    input_mask_array.append(att_mask)\n",
    "  # Convertion to Tensor\n",
    "  input_ids = torch.tensor(input_ids) \n",
    "  input_mask_array = torch.tensor(input_mask_array)\n",
    "  label_id_array = torch.tensor(label_id_array, dtype=torch.long)\n",
    "\n",
    "  # Building the TensorDataset\n",
    "  dataset = TensorDataset(input_ids, input_mask_array, label_id_array)\n",
    "\n",
    "  if do_shuffle:\n",
    "    sampler = RandomSampler\n",
    "  else:\n",
    "    sampler = SequentialSampler\n",
    "\n",
    "  # Building the DataLoader\n",
    "  return DataLoader(\n",
    "              dataset,  # The training samples.\n",
    "              sampler = sampler(dataset), \n",
    "              batch_size = batch_size) # Trains with this batch size.\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Do3O-VeefT3g"
   },
   "source": [
    "Convert the input examples into DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "4c-nsMXlKX-D"
   },
   "outputs": [],
   "source": [
    "label_map = {}\n",
    "for (i, label) in enumerate(label_list):\n",
    "  label_map[label] = i\n",
    "#------------------------------\n",
    "#   Load the train dataset\n",
    "#------------------------------\n",
    "train_examples = labeled_examples\n",
    "#The labeled (train) dataset is assigned with a mask set to True\n",
    "\n",
    "\n",
    "train_dataloader = generate_data_loader(train_examples, label_map, do_shuffle = True, balance_label_examples = apply_balance)\n",
    "\n",
    "#------------------------------\n",
    "#   Load the test dataset\n",
    "#------------------------------\n",
    "#The labeled (test) dataset is assigned with a mask set to True\n",
    "\n",
    "test_dataloader = generate_data_loader(test_examples, label_map, do_shuffle = False, balance_label_examples = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Ihcw3vquaQm"
   },
   "source": [
    "We define the Generator and Discriminator as discussed in https://www.aclweb.org/anthology/2020.acl-main.191/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uje9s2zQunFc"
   },
   "source": [
    "We instantiate the Discriminator and Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Ylz5rvqE3U2S"
   },
   "outputs": [],
   "source": [
    "# The config file is required to get the dimension of the vector produced by \n",
    "# the underlying transformer\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "hidden_size = int(config.hidden_size)\n",
    "# Define the number and width of hidden layers\n",
    "\n",
    "# Put everything in the GPU if available\n",
    "if torch.cuda.is_available():    \n",
    "  transformer.cuda()\n",
    "  if multi_gpu:\n",
    "    transformer = torch.nn.DataParallel(transformer)\n",
    "\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VG3qzp2-usZE"
   },
   "source": [
    "Let's go with the training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "PbgCcotT2_79"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NhqylHGK3Va4",
    "outputId": "933381ba-a4b8-4131-8ea0-391fac6880dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n",
      "  Batch    10  of    312.    Elapsed: 0:00:03.\n",
      "  Batch    20  of    312.    Elapsed: 0:00:06.\n",
      "  Batch    30  of    312.    Elapsed: 0:00:09.\n",
      "  Batch    40  of    312.    Elapsed: 0:00:12.\n",
      "  Batch    50  of    312.    Elapsed: 0:00:16.\n",
      "  Batch    60  of    312.    Elapsed: 0:00:19.\n",
      "  Batch    70  of    312.    Elapsed: 0:00:22.\n",
      "  Batch    80  of    312.    Elapsed: 0:00:25.\n",
      "  Batch    90  of    312.    Elapsed: 0:00:28.\n",
      "  Batch   100  of    312.    Elapsed: 0:00:31.\n",
      "  Batch   110  of    312.    Elapsed: 0:00:34.\n",
      "  Batch   120  of    312.    Elapsed: 0:00:37.\n",
      "  Batch   130  of    312.    Elapsed: 0:00:40.\n",
      "  Batch   140  of    312.    Elapsed: 0:00:44.\n",
      "  Batch   150  of    312.    Elapsed: 0:00:47.\n",
      "  Batch   160  of    312.    Elapsed: 0:00:50.\n",
      "  Batch   170  of    312.    Elapsed: 0:00:53.\n",
      "  Batch   180  of    312.    Elapsed: 0:00:56.\n",
      "  Batch   190  of    312.    Elapsed: 0:00:59.\n",
      "  Batch   200  of    312.    Elapsed: 0:01:02.\n",
      "  Batch   210  of    312.    Elapsed: 0:01:06.\n",
      "  Batch   220  of    312.    Elapsed: 0:01:09.\n",
      "  Batch   230  of    312.    Elapsed: 0:01:12.\n",
      "  Batch   240  of    312.    Elapsed: 0:01:15.\n",
      "  Batch   250  of    312.    Elapsed: 0:01:18.\n",
      "  Batch   260  of    312.    Elapsed: 0:01:21.\n",
      "  Batch   270  of    312.    Elapsed: 0:01:24.\n",
      "  Batch   280  of    312.    Elapsed: 0:01:27.\n",
      "  Batch   290  of    312.    Elapsed: 0:01:31.\n",
      "  Batch   300  of    312.    Elapsed: 0:01:34.\n",
      "  Batch   310  of    312.    Elapsed: 0:01:37.\n",
      "\n",
      "  Training epcoh took: 0:01:37\n",
      "\n",
      "Running Test...\n",
      "all_preds\n",
      "[2 4 1 ... 4 3 4]\n",
      "all_labels\n",
      "[0 0 0 ... 4 4 4]\n",
      "  Accuracy: 0.419\n",
      "  Test Loss: 1.285\n",
      "  Test took: 0:00:17\n",
      "\n",
      "======== Epoch 2 / 5 ========\n",
      "Training...\n",
      "  Batch    10  of    312.    Elapsed: 0:00:03.\n",
      "  Batch    20  of    312.    Elapsed: 0:00:06.\n",
      "  Batch    30  of    312.    Elapsed: 0:00:09.\n",
      "  Batch    40  of    312.    Elapsed: 0:00:13.\n",
      "  Batch    50  of    312.    Elapsed: 0:00:16.\n",
      "  Batch    60  of    312.    Elapsed: 0:00:19.\n",
      "  Batch    70  of    312.    Elapsed: 0:00:22.\n",
      "  Batch    80  of    312.    Elapsed: 0:00:25.\n",
      "  Batch    90  of    312.    Elapsed: 0:00:28.\n",
      "  Batch   100  of    312.    Elapsed: 0:00:31.\n",
      "  Batch   110  of    312.    Elapsed: 0:00:34.\n",
      "  Batch   120  of    312.    Elapsed: 0:00:38.\n",
      "  Batch   130  of    312.    Elapsed: 0:00:41.\n",
      "  Batch   140  of    312.    Elapsed: 0:00:44.\n",
      "  Batch   150  of    312.    Elapsed: 0:00:47.\n",
      "  Batch   160  of    312.    Elapsed: 0:00:50.\n",
      "  Batch   170  of    312.    Elapsed: 0:00:53.\n",
      "  Batch   180  of    312.    Elapsed: 0:00:56.\n",
      "  Batch   190  of    312.    Elapsed: 0:01:00.\n",
      "  Batch   200  of    312.    Elapsed: 0:01:03.\n",
      "  Batch   210  of    312.    Elapsed: 0:01:06.\n",
      "  Batch   220  of    312.    Elapsed: 0:01:09.\n",
      "  Batch   230  of    312.    Elapsed: 0:01:12.\n",
      "  Batch   240  of    312.    Elapsed: 0:01:15.\n",
      "  Batch   250  of    312.    Elapsed: 0:01:18.\n",
      "  Batch   260  of    312.    Elapsed: 0:01:22.\n",
      "  Batch   270  of    312.    Elapsed: 0:01:25.\n",
      "  Batch   280  of    312.    Elapsed: 0:01:28.\n",
      "  Batch   290  of    312.    Elapsed: 0:01:31.\n",
      "  Batch   300  of    312.    Elapsed: 0:01:34.\n",
      "  Batch   310  of    312.    Elapsed: 0:01:37.\n",
      "\n",
      "  Training epcoh took: 0:01:38\n",
      "\n",
      "Running Test...\n",
      "all_preds\n",
      "[1 0 0 ... 4 3 4]\n",
      "all_labels\n",
      "[0 0 0 ... 4 4 4]\n",
      "  Accuracy: 0.477\n",
      "  Test Loss: 1.171\n",
      "  Test took: 0:00:17\n",
      "\n",
      "======== Epoch 3 / 5 ========\n",
      "Training...\n",
      "  Batch    10  of    312.    Elapsed: 0:00:03.\n",
      "  Batch    20  of    312.    Elapsed: 0:00:06.\n",
      "  Batch    30  of    312.    Elapsed: 0:00:09.\n",
      "  Batch    40  of    312.    Elapsed: 0:00:13.\n",
      "  Batch    50  of    312.    Elapsed: 0:00:16.\n",
      "  Batch    60  of    312.    Elapsed: 0:00:19.\n",
      "  Batch    70  of    312.    Elapsed: 0:00:22.\n",
      "  Batch    80  of    312.    Elapsed: 0:00:25.\n",
      "  Batch    90  of    312.    Elapsed: 0:00:28.\n",
      "  Batch   100  of    312.    Elapsed: 0:00:31.\n",
      "  Batch   110  of    312.    Elapsed: 0:00:34.\n",
      "  Batch   120  of    312.    Elapsed: 0:00:38.\n",
      "  Batch   130  of    312.    Elapsed: 0:00:41.\n",
      "  Batch   140  of    312.    Elapsed: 0:00:44.\n",
      "  Batch   150  of    312.    Elapsed: 0:00:47.\n",
      "  Batch   160  of    312.    Elapsed: 0:00:50.\n",
      "  Batch   170  of    312.    Elapsed: 0:00:53.\n",
      "  Batch   180  of    312.    Elapsed: 0:00:56.\n",
      "  Batch   190  of    312.    Elapsed: 0:01:00.\n",
      "  Batch   200  of    312.    Elapsed: 0:01:03.\n",
      "  Batch   210  of    312.    Elapsed: 0:01:06.\n",
      "  Batch   220  of    312.    Elapsed: 0:01:09.\n",
      "  Batch   230  of    312.    Elapsed: 0:01:12.\n",
      "  Batch   240  of    312.    Elapsed: 0:01:15.\n",
      "  Batch   250  of    312.    Elapsed: 0:01:18.\n",
      "  Batch   260  of    312.    Elapsed: 0:01:22.\n",
      "  Batch   270  of    312.    Elapsed: 0:01:25.\n",
      "  Batch   280  of    312.    Elapsed: 0:01:28.\n",
      "  Batch   290  of    312.    Elapsed: 0:01:31.\n",
      "  Batch   300  of    312.    Elapsed: 0:01:34.\n",
      "  Batch   310  of    312.    Elapsed: 0:01:37.\n",
      "\n",
      "  Training epcoh took: 0:01:38\n",
      "\n",
      "Running Test...\n",
      "all_preds\n",
      "[3 4 1 ... 4 3 4]\n",
      "all_labels\n",
      "[0 0 0 ... 4 4 4]\n",
      "  Accuracy: 0.455\n",
      "  Test Loss: 1.221\n",
      "  Test took: 0:00:17\n",
      "\n",
      "======== Epoch 4 / 5 ========\n",
      "Training...\n",
      "  Batch    10  of    312.    Elapsed: 0:00:03.\n",
      "  Batch    20  of    312.    Elapsed: 0:00:06.\n",
      "  Batch    30  of    312.    Elapsed: 0:00:09.\n",
      "  Batch    40  of    312.    Elapsed: 0:00:13.\n",
      "  Batch    50  of    312.    Elapsed: 0:00:16.\n",
      "  Batch    60  of    312.    Elapsed: 0:00:19.\n",
      "  Batch    70  of    312.    Elapsed: 0:00:22.\n",
      "  Batch    80  of    312.    Elapsed: 0:00:25.\n",
      "  Batch    90  of    312.    Elapsed: 0:00:28.\n",
      "  Batch   100  of    312.    Elapsed: 0:00:31.\n",
      "  Batch   110  of    312.    Elapsed: 0:00:34.\n",
      "  Batch   120  of    312.    Elapsed: 0:00:38.\n",
      "  Batch   130  of    312.    Elapsed: 0:00:41.\n",
      "  Batch   140  of    312.    Elapsed: 0:00:44.\n",
      "  Batch   150  of    312.    Elapsed: 0:00:47.\n",
      "  Batch   160  of    312.    Elapsed: 0:00:50.\n",
      "  Batch   170  of    312.    Elapsed: 0:00:53.\n",
      "  Batch   180  of    312.    Elapsed: 0:00:56.\n",
      "  Batch   190  of    312.    Elapsed: 0:01:00.\n",
      "  Batch   200  of    312.    Elapsed: 0:01:03.\n",
      "  Batch   210  of    312.    Elapsed: 0:01:06.\n",
      "  Batch   220  of    312.    Elapsed: 0:01:09.\n",
      "  Batch   230  of    312.    Elapsed: 0:01:12.\n",
      "  Batch   240  of    312.    Elapsed: 0:01:15.\n",
      "  Batch   250  of    312.    Elapsed: 0:01:18.\n",
      "  Batch   260  of    312.    Elapsed: 0:01:22.\n",
      "  Batch   270  of    312.    Elapsed: 0:01:25.\n",
      "  Batch   280  of    312.    Elapsed: 0:01:28.\n",
      "  Batch   290  of    312.    Elapsed: 0:01:31.\n",
      "  Batch   300  of    312.    Elapsed: 0:01:34.\n",
      "  Batch   310  of    312.    Elapsed: 0:01:37.\n",
      "\n",
      "  Training epcoh took: 0:01:38\n",
      "\n",
      "Running Test...\n",
      "all_preds\n",
      "[2 0 0 ... 4 3 4]\n",
      "all_labels\n",
      "[0 0 0 ... 4 4 4]\n",
      "  Accuracy: 0.502\n",
      "  Test Loss: 1.144\n",
      "  Test took: 0:00:17\n",
      "\n",
      "======== Epoch 5 / 5 ========\n",
      "Training...\n",
      "  Batch    10  of    312.    Elapsed: 0:00:03.\n",
      "  Batch    20  of    312.    Elapsed: 0:00:06.\n",
      "  Batch    30  of    312.    Elapsed: 0:00:09.\n",
      "  Batch    40  of    312.    Elapsed: 0:00:13.\n",
      "  Batch    50  of    312.    Elapsed: 0:00:16.\n",
      "  Batch    60  of    312.    Elapsed: 0:00:19.\n",
      "  Batch    70  of    312.    Elapsed: 0:00:22.\n",
      "  Batch    80  of    312.    Elapsed: 0:00:25.\n",
      "  Batch    90  of    312.    Elapsed: 0:00:28.\n",
      "  Batch   100  of    312.    Elapsed: 0:00:31.\n",
      "  Batch   110  of    312.    Elapsed: 0:00:35.\n",
      "  Batch   120  of    312.    Elapsed: 0:00:38.\n",
      "  Batch   130  of    312.    Elapsed: 0:00:41.\n",
      "  Batch   140  of    312.    Elapsed: 0:00:44.\n",
      "  Batch   150  of    312.    Elapsed: 0:00:47.\n",
      "  Batch   160  of    312.    Elapsed: 0:00:50.\n",
      "  Batch   170  of    312.    Elapsed: 0:00:53.\n",
      "  Batch   180  of    312.    Elapsed: 0:00:56.\n",
      "  Batch   190  of    312.    Elapsed: 0:01:00.\n",
      "  Batch   200  of    312.    Elapsed: 0:01:03.\n",
      "  Batch   210  of    312.    Elapsed: 0:01:06.\n",
      "  Batch   220  of    312.    Elapsed: 0:01:09.\n",
      "  Batch   230  of    312.    Elapsed: 0:01:12.\n",
      "  Batch   240  of    312.    Elapsed: 0:01:15.\n",
      "  Batch   250  of    312.    Elapsed: 0:01:18.\n",
      "  Batch   260  of    312.    Elapsed: 0:01:22.\n",
      "  Batch   270  of    312.    Elapsed: 0:01:25.\n",
      "  Batch   280  of    312.    Elapsed: 0:01:28.\n",
      "  Batch   290  of    312.    Elapsed: 0:01:31.\n",
      "  Batch   300  of    312.    Elapsed: 0:01:34.\n",
      "  Batch   310  of    312.    Elapsed: 0:01:37.\n",
      "\n",
      "  Training epcoh took: 0:01:38\n",
      "\n",
      "Running Test...\n",
      "all_preds\n",
      "[1 0 0 ... 4 4 4]\n",
      "all_labels\n",
      "[0 0 0 ... 4 4 4]\n",
      "  Accuracy: 0.502\n",
      "  Test Loss: 1.220\n",
      "  Test took: 0:00:17\n"
     ]
    }
   ],
   "source": [
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "#models parameters\n",
    "transformer_vars = [i for i in transformer.parameters()]\n",
    "\n",
    "\n",
    "#optimizer\n",
    "optimizer = torch.optim.AdamW(transformer_vars, lr=learning_rate_discriminator)\n",
    "\n",
    "#scheduler\n",
    "if apply_scheduler:\n",
    "  num_train_examples = len(train_examples)\n",
    "  num_train_steps = int(num_train_examples / batch_size * num_train_epochs)\n",
    "  num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
    "  scheduler = get_constant_schedule_with_warmup(optimizer, \n",
    "                                           num_warmup_steps = num_warmup_steps)\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, num_train_epochs):\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, num_train_epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    tr_loss  = 0\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    transformer.train() \n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every print_each_n_step batches.\n",
    "        if step % print_each_n_step == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        real_batch_size = b_input_ids.shape[0]\n",
    "     \n",
    "        # Encode real data in the Transformer\n",
    "        model_outputs = transformer(b_input_ids, attention_mask=b_input_mask,labels=b_labels)\n",
    "        step_loss=model_outputs[0]\n",
    "        \n",
    "\n",
    "        #---------------------------------\n",
    "        #  OPTIMIZATION\n",
    "        #---------------------------------\n",
    "        # Avoid gradient accumulation\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Calculate weigth updates\n",
    "        # retain_graph=True is required since the underlying graph will be deleted after backward\n",
    "        step_loss.backward() \n",
    "                \n",
    "        # Apply modifications\n",
    "        optimizer.step()\n",
    "        # A detail log of the individual losses\n",
    "        #print(\"{0:.4f}\\t{1:.4f}\\t{2:.4f}\\t{3:.4f}\\t{4:.4f}\".\n",
    "        #      format(D_L_Supervised, D_L_unsupervised1U, D_L_unsupervised2U,\n",
    "        #             g_loss_d, g_feat_reg))\n",
    "\n",
    "        # Save the losses to print them later\n",
    "        tr_loss += step_loss.item()\n",
    "\n",
    "        # Update the learning rate with the scheduler\n",
    "        if apply_scheduler:\n",
    "          scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = tr_loss / len(train_dataloader)\n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #     TEST ON THE EVALUATION DATASET\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our test set.\n",
    "    print(\"\")\n",
    "    print(\"Running Test...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    transformer.eval() #maybe redundant\n",
    "\n",
    "    # Tracking variables \n",
    "    total_test_accuracy = 0\n",
    "   \n",
    "    total_test_loss = 0\n",
    "    nb_test_steps = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels_ids = []\n",
    "\n",
    "    #loss\n",
    "    nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in test_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():    \n",
    "            output=transformer(b_input_ids, attention_mask=b_input_mask,labels=b_labels)\n",
    "            tmp_eval_loss, logits = output[0],output[1]\n",
    "            # Accumulate the test loss.            \n",
    "        # Accumulate the predictions and the input labels\n",
    "        preds = np.argmax(logits.to('cpu'), axis=1)\n",
    "        all_preds += preds.detach().cpu()\n",
    "        all_labels_ids += b_labels.detach().cpu()\n",
    "        total_test_loss+=tmp_eval_loss.item()\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    all_preds = torch.stack(all_preds).numpy()\n",
    "    print('all_preds')\n",
    "    print(all_preds)\n",
    "    all_labels_ids = torch.stack(all_labels_ids).numpy()\n",
    "    print('all_labels')\n",
    "    print(all_labels_ids)\n",
    "    test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n",
    "    print(\"  Accuracy: {0:.3f}\".format(test_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
    "    avg_test_loss = avg_test_loss\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    test_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Test Loss: {0:.3f}\".format(avg_test_loss))\n",
    "    print(\"  Test took: {:}\".format(test_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Valid. Loss': avg_test_loss,\n",
    "            'Valid. Accur.': test_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Test Time': test_time\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "dDm9NProRB4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1, 'Valid. Loss': 1.2845545972988104, 'Valid. Accur.': 0.4188, 'Training Time': '0:01:37', 'Test Time': '0:00:17'}\n",
      "{'epoch': 2, 'Valid. Loss': 1.171353978336237, 'Valid. Accur.': 0.4768, 'Training Time': '0:01:38', 'Test Time': '0:00:17'}\n",
      "{'epoch': 3, 'Valid. Loss': 1.2208026575434738, 'Valid. Accur.': 0.4546, 'Training Time': '0:01:38', 'Test Time': '0:00:17'}\n",
      "{'epoch': 4, 'Valid. Loss': 1.1437237737285104, 'Valid. Accur.': 0.5022, 'Training Time': '0:01:38', 'Test Time': '0:00:17'}\n",
      "{'epoch': 5, 'Valid. Loss': 1.219955934081108, 'Valid. Accur.': 0.502, 'Training Time': '0:01:38', 'Test Time': '0:00:17'}\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:09:32 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "for stat in training_stats:\n",
    "  print(stat)\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hchcz8Og6hey"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5czyqydU6pV3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "GPT2_pytorch_Amazon",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "129fa07e06f948619468a9f05b0fb1cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a094026b4e74437a099252eaa523a0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89262b565bd74339a096533024105135",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e430d1cecc0f45a583294e3a06c4c405",
      "value": 3
     }
    },
    "1e228d8f3f5e4c7da48113659ef20d46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20814569beb741bb88e33279fc065e3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2339fae914374b5d9ad722c51d1587a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2434bd843c194f9a98a52ed61f18dc6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_62c32181e5454be4853204fc34d2e005",
       "IPY_MODEL_1a094026b4e74437a099252eaa523a0a",
       "IPY_MODEL_c3bc29808fc84322a5ed0eadec2a395e"
      ],
      "layout": "IPY_MODEL_129fa07e06f948619468a9f05b0fb1cd"
     }
    },
    "27343e20465f4baca64bbb06059018ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "32ebaebc1b9f4c38a9b09b622b74bb4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a46736657d3f4dd9a3588417df8f2b82",
      "placeholder": "​",
      "style": "IPY_MODEL_fdbfe0cba9f34fee9b676a9b0e4e2c92",
      "value": "100%"
     }
    },
    "343014c346ff4a39b498b1c7637feb96": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47ba2d37dbb84f95be3a9c157d5debb3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b92fbbaa843493ba899a9c82b500f04": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "588b4eb8e8644a659d2e3d7f03ead81b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62c32181e5454be4853204fc34d2e005": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc56de84e1944f4986e568963cad3859",
      "placeholder": "​",
      "style": "IPY_MODEL_ee2079f01f524cf1930cf7840f8dd865",
      "value": "100%"
     }
    },
    "83b2a8bf9a584512950b8c537832c24b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89262b565bd74339a096533024105135": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97b6d1467c0446b1bf69495cb81a6010": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a033b282afd4425fb82b4bca73c23744": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f1a4c983573441529ab0de9a457d9dc7",
      "placeholder": "​",
      "style": "IPY_MODEL_c084ad84d5d84ad48021c21bd260557d",
      "value": " 5000/5000 [00:01&lt;00:00, 4044.76it/s]"
     }
    },
    "a46736657d3f4dd9a3588417df8f2b82": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b355e5360890461e97f602e7eeb558ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83b2a8bf9a584512950b8c537832c24b",
      "placeholder": "​",
      "style": "IPY_MODEL_fbda94b20c044d298dc93b228d56d14c",
      "value": " 199426/199426 [00:52&lt;00:00, 4378.67it/s]"
     }
    },
    "b5e9ed2012ab402786d1d100e8a962fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c981c49a377444f5b3183ce1b1ec4a17",
       "IPY_MODEL_d0cc3e8debd84b6d9a82fa82600c1390",
       "IPY_MODEL_a033b282afd4425fb82b4bca73c23744"
      ],
      "layout": "IPY_MODEL_1e228d8f3f5e4c7da48113659ef20d46"
     }
    },
    "bc56de84e1944f4986e568963cad3859": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c084ad84d5d84ad48021c21bd260557d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c3bc29808fc84322a5ed0eadec2a395e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97b6d1467c0446b1bf69495cb81a6010",
      "placeholder": "​",
      "style": "IPY_MODEL_20814569beb741bb88e33279fc065e3e",
      "value": " 3/3 [00:00&lt;00:00, 72.96it/s]"
     }
    },
    "c981c49a377444f5b3183ce1b1ec4a17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b92fbbaa843493ba899a9c82b500f04",
      "placeholder": "​",
      "style": "IPY_MODEL_27343e20465f4baca64bbb06059018ec",
      "value": "100%"
     }
    },
    "d0b3f99b999e4404b368ffef20afd215": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_32ebaebc1b9f4c38a9b09b622b74bb4a",
       "IPY_MODEL_e92970194bf147bcafd1ce5e2cd40f6a",
       "IPY_MODEL_b355e5360890461e97f602e7eeb558ec"
      ],
      "layout": "IPY_MODEL_588b4eb8e8644a659d2e3d7f03ead81b"
     }
    },
    "d0cc3e8debd84b6d9a82fa82600c1390": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_343014c346ff4a39b498b1c7637feb96",
      "max": 5000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2339fae914374b5d9ad722c51d1587a6",
      "value": 5000
     }
    },
    "e19df474123f435abdae9508b80ad00a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e430d1cecc0f45a583294e3a06c4c405": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e92970194bf147bcafd1ce5e2cd40f6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47ba2d37dbb84f95be3a9c157d5debb3",
      "max": 199426,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e19df474123f435abdae9508b80ad00a",
      "value": 199426
     }
    },
    "ee2079f01f524cf1930cf7840f8dd865": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f1a4c983573441529ab0de9a457d9dc7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbda94b20c044d298dc93b228d56d14c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fdbfe0cba9f34fee9b676a9b0e4e2c92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
